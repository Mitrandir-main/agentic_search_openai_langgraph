import json
from langgraph.graph import StateGraph, END
from langchain_core.messages import HumanMessage
from advanced_legal_agents import (
    LegalAgentState,
    create_legal_supervisor,
    create_legal_researcher_agent,
    create_legal_analyst_agent,
    create_precedent_finder_agent,
    create_document_reviewer_agent,
    create_legal_conciliator_agent,
    get_legal_members,
    determine_legal_workflow,
    create_legal_memory_manager
)
from bulgarian_legal_domains import BULGARIAN_LEGAL_DOMAINS
from datetime import datetime
import logging

# Set up logging for legal research tracking
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def build_enhanced_legal_graph():
    """Build enhanced legal research graph with Conciliator pattern"""
    
    # Create all agents
    supervisor_chain = create_legal_supervisor()
    legal_researcher_node = create_legal_researcher_agent()
    legal_analyst_node = create_legal_analyst_agent()
    precedent_finder_node = create_precedent_finder_agent()
    document_reviewer_node = create_document_reviewer_agent()
    legal_conciliator_node = create_legal_conciliator_agent()
    
    # Build the graph
    graph_builder = StateGraph(LegalAgentState)
    
    # Add all nodes
    graph_builder.add_node("Legal_Supervisor", supervisor_chain)
    graph_builder.add_node("Legal_Researcher", legal_researcher_node)
    graph_builder.add_node("Legal_Analyst", legal_analyst_node)
    graph_builder.add_node("Precedent_Finder", precedent_finder_node)
    graph_builder.add_node("Document_Reviewer", document_reviewer_node)
    graph_builder.add_node("Legal_Conciliator", legal_conciliator_node)
    
    # Set up edges for agent collaboration
    members = get_legal_members()
    for member in members:
        graph_builder.add_edge(member, "Legal_Supervisor")
    
    # Conditional map for routing
    conditional_map = {k: k for k in members}
    conditional_map["FINISH"] = END
    conditional_map["CONCILIATE"] = "Legal_Conciliator"
    
    # Enhanced routing function with Conciliator pattern
    def route_legal_supervisor(x):
        """Enhanced routing with conflict detection and conciliation"""
        try:
            if isinstance(x, dict):
                if "args" in x:
                    next_action = x["args"].get("next", "FINISH")
                elif "next" in x:
                    next_action = x["next"]
                else:
                    next_action = "FINISH"
            else:
                next_action = "FINISH"
            
            # Check if we need conciliation (multiple conflicting results)
            if hasattr(x, 'get') and x.get('iterations', 0) >= 3:
                # If we've had multiple iterations, consider conciliation
                messages = x.get('messages', [])
                if len(messages) >= 4:  # Multiple agent responses
                    logger.info("Multiple iterations detected, considering conciliation")
                    return "Legal_Conciliator"
            
            logger.info(f"Routing to: {next_action}")
            return next_action
            
        except Exception as e:
            logger.error(f"Routing error: {e}")
            return END
    
    # Add conditional edges with enhanced routing
    graph_builder.add_conditional_edges(
        "Legal_Supervisor", 
        route_legal_supervisor, 
        conditional_map
    )
    
    # Add edge from Conciliator back to supervisor or end
    graph_builder.add_edge("Legal_Conciliator", END)
    
    # Set entry point
    graph_builder.set_entry_point("Legal_Supervisor")
    
    # Compile the graph
    graph = graph_builder.compile()
    
    return graph

def visualize_legal_graph():
    """Generate visualization for the legal research graph"""
    graph = build_enhanced_legal_graph()
    
    try:
        # Try to create PNG visualization
        png_data = graph.get_graph().draw_mermaid_png()
        with open("legal_graph_visualization.png", "wb") as f:
            f.write(png_data)
        print("‚úÖ Legal graph visualization saved as 'legal_graph_visualization.png'")
        
        # Create Mermaid text format
        mermaid_syntax = graph.get_graph().draw_mermaid()
        with open("legal_graph_visualization.md", "w") as f:
            f.write("# üèõÔ∏è Enhanced Bulgarian Legal Research Graph\n\n")
            f.write("```mermaid\n")
            f.write(mermaid_syntax)
            f.write("\n```\n\n")
            f.write("## üìã Agent Descriptions\n\n")
            f.write("- **Legal_Supervisor**: Orchestrates legal research workflow\n")
            f.write("- **Legal_Researcher**: Searches Bulgarian legal domains (lex.bg, vks.bg, etc.)\n")
            f.write("- **Legal_Analyst**: Analyzes legal documents and extracts key information\n")
            f.write("- **Precedent_Finder**: Finds relevant court decisions and precedents\n")
            f.write("- **Document_Reviewer**: Reviews documents for citations and legal accuracy\n")
            f.write("- **Legal_Conciliator**: Resolves conflicts between agent findings\n")
            
        print("‚úÖ Legal graph mermaid saved as 'legal_graph_visualization.md'")
        
        return mermaid_syntax
        
    except Exception as e:
        print(f"‚ùå Could not generate PNG visualization: {e}")
        # Fallback to text representation
        mermaid_syntax = graph.get_graph().draw_mermaid()
        print("üìä Legal Graph Structure:")
        print(mermaid_syntax)
        return mermaid_syntax

def run_legal_research(query: str, workflow_type: str = "auto"):
    """Run enhanced legal research with workflow optimization"""
    
    # Initialize legal memory
    legal_memory = create_legal_memory_manager()
    
    # Determine optimal workflow
    if workflow_type == "auto":
        workflow = determine_legal_workflow(query)
        logger.info(f"Determined workflow: {workflow['type']}")
    else:
        workflow = {"type": workflow_type, "agents": get_legal_members()}
    
    # Enhanced initial state
    initial_state = {
        "messages": [HumanMessage(content=f"""
üèõÔ∏è **–ü–†–ê–í–ù–ê –ó–ê–Ø–í–ö–ê**: {query}

**–ó–ê–î–ê–ß–ê**: –ú–æ–ª—è, –∏–∑–≤—ä—Ä—à–µ—Ç–µ –∑–∞–¥—ä–ª–±–æ—á–µ–Ω–æ –ø—Ä–∞–≤–Ω–æ –∏–∑—Å–ª–µ–¥–≤–∞–Ω–µ —Ñ–æ–∫—É—Å–∏—Ä–∞–Ω–æ –≤—ä—Ä—Ö—É:
- –ë—ä–ª–≥–∞—Ä—Å–∫–æ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—Å—Ç–≤–æ –∏ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–∏ –∞–∫—Ç–æ–≤–µ
- –°—ä–¥–µ–±–Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–∞ –æ—Ç –í–ö–°, –í–ê–° –∏ –¥—Ä—É–≥–∏ –±—ä–ª–≥–∞—Ä—Å–∫–∏ —Å—ä–¥–∏–ª–∏—â–∞  
- –ê–∫—Ç—É–∞–ª–Ω–∏ –ø—Ä–∞–≤–Ω–∏ –ø–æ–∑–∏—Ü–∏–∏ (2024-2025)
- –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–∞–Ω–∏ –ø—Ä–∞–≤–Ω–∏ –¥–æ–º–µ–π–Ω–∏: {', '.join(BULGARIAN_LEGAL_DOMAINS.keys())}

**–ò–ó–ò–°–ö–í–ê–ù–ò–Ø**:
1. –¢—ä—Ä—Å–µ—Ç–µ —Å–∞–º–æ –≤ –±—ä–ª–≥–∞—Ä—Å–∫–∏ –ø—Ä–∞–≤–Ω–∏ –∏–∑—Ç–æ—á–Ω–∏—Ü–∏
2. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–µ—Ç–µ —Ç–æ—á–Ω–∏ —Ü–∏—Ç–∞—Ç–∏ (—á–ª., –∞–ª., —Ç.)
3. –ê–Ω–∞–ª–∏–∑–∏—Ä–∞–π—Ç–µ —Å—ä–¥–µ–±–Ω–∞—Ç–∞ –ø—Ä–∞–∫—Ç–∏–∫–∞
4. –û—Ü–µ–Ω–µ—Ç–µ –ø—Ä–∞–≤–Ω–∏—Ç–µ —Ä–∏—Å–∫–æ–≤–µ –∏ –ø–æ—Å–ª–µ–¥–∏—Ü–∏
5. –î–∞–π—Ç–µ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–µ–ø–æ—Ä—ä–∫–∏

**WORKFLOW**: {workflow['type']}
""")],
        "next": "Legal_Researcher",  # Start with research
        "legal_area": None,
        "confidence": 0.0,
        "sources_checked": [],
        "iterations": 0,
        "max_iterations": 6,
        "final_decision": None,
        "citations": []
    }
    
    # Build and run graph
    graph = build_enhanced_legal_graph()
    
    try:
        logger.info(f"üîç Starting legal research for: {query}")
        response = graph.invoke(initial_state)
        
        # Process and format results
        result = format_legal_results(response, legal_memory)
        
        logger.info("‚úÖ Legal research completed")
        return result
        
    except Exception as e:
        logger.error(f"‚ùå Error during legal research: {e}")
        return f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –ø—Ä–∞–≤–Ω–æ—Ç–æ –∏–∑—Å–ª–µ–¥–≤–∞–Ω–µ: {str(e)}"

def run_legal_research_with_streaming(query: str):
    """Run legal research with streaming for real-time updates"""
    
    print("üèõÔ∏è –ó–∞–ø–æ—á–≤–∞–Ω–µ –Ω–∞ –ø—Ä–∞–≤–Ω–æ –∏–∑—Å–ª–µ–¥–≤–∞–Ω–µ...\n")
    
    # Track progress
    steps_completed = []
    
    try:
        graph = build_enhanced_legal_graph()
        
        initial_state = {
            "messages": [HumanMessage(content=query)],
            "next": "Legal_Researcher",
            "legal_area": None,
            "confidence": 0.0,
            "sources_checked": [],
            "iterations": 0,
            "max_iterations": 6,
            "final_decision": None,
            "citations": []
        }
        
        # Stream the execution
        for step, event in enumerate(graph.stream(initial_state)):
            for key, value in event.items():
                if key != "__end__":
                    steps_completed.append(key)
                    print(f"üìã **–°—Ç—ä–ø–∫–∞ {step + 1} - {key}**:")
                    
                    # Extract meaningful information from agent responses
                    if isinstance(value, dict) and 'messages' in value:
                        last_message = value['messages'][-1] if value['messages'] else None
                        if last_message and hasattr(last_message, 'content'):
                            # Truncate long responses for streaming
                            content = last_message.content[:300] + "..." if len(last_message.content) > 300 else last_message.content
                            print(f"   {content}")
                    
                    print("---")
        
        # Get final result
        final_response = graph.invoke(initial_state)
        
        print(f"\n‚úÖ **–ó–∞–≤—ä—Ä—à–µ–Ω–æ**: –û–±—Ä–∞–±–æ—Ç–µ–Ω–∏ {len(steps_completed)} —Å—Ç—ä–ø–∫–∏")
        print(f"üìä **–ê–≥–µ–Ω—Ç–∏**: {', '.join(set(steps_completed))}")
        
        return run_legal_research(query)  # Use the regular formatting
        
    except Exception as e:
        print(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ streaming –∏–∑–ø—ä–ª–Ω–µ–Ω–∏–µ: {e}")
        return run_legal_research(query)  # Fallback

def format_legal_results(response: dict, legal_memory) -> str:
    """Format legal research results with enhanced structure"""
    
    if not response.get('messages'):
        return "‚ùå –ù—è–º–∞ –≥–µ–Ω–µ—Ä–∏—Ä–∞–Ω –æ—Ç–≥–æ–≤–æ—Ä."
    
    # Get all messages for comprehensive analysis
    messages = response['messages']
    
    # Extract content from all agent responses
    agent_responses = {}
    citations_found = set()
    sources_used = set()
    
    for message in messages:
        if hasattr(message, 'name') and hasattr(message, 'content'):
            agent_name = message.name
            content = message.content
            
            agent_responses[agent_name] = content
            
            # Extract citations
            import re
            citations = re.findall(r'—á–ª\.\s*\d+(?:,\s*–∞–ª\.\s*\d+)?(?:,\s*—Ç\.\s*\d+)?', content, re.IGNORECASE)
            citations_found.update(citations)
            
            # Extract domain mentions  
            for domain_key, domain_info in BULGARIAN_LEGAL_DOMAINS.items():
                domain_found = False
                
                # Check domain in content
                if domain_info.get('domain', '') in content:
                    domain_found = True
                
                # Check search patterns if they exist
                search_patterns = domain_info.get('search_patterns', [])
                if search_patterns and any(pattern in content for pattern in search_patterns):
                    domain_found = True
                    
                if domain_found:
                    sources_used.add(domain_info.get('description', domain_key))
    
    # Get final response content
    final_content = messages[-1].content if messages else "–ù—è–º–∞ —Ñ–∏–Ω–∞–ª–µ–Ω –æ—Ç–≥–æ–≤–æ—Ä"
    
    # Generate comprehensive report
    result = f"""
# üèõÔ∏è **–ü–†–ê–í–ù–û –ò–ó–°–õ–ï–î–í–ê–ù–ï - –†–ï–ó–£–õ–¢–ê–¢–ò**

## üìÖ **–ú–µ—Ç–∞–¥–∞–Ω–Ω–∏ –Ω–∞ –∏–∑—Å–ª–µ–¥–≤–∞–Ω–µ—Ç–æ**
- **–î–∞—Ç–∞ –Ω–∞ –∏–∑—Å–ª–µ–¥–≤–∞–Ω–µ**: {datetime.now().strftime("%d.%m.%Y %H:%M")}
- **–ë—Ä–æ–π –∞–≥–µ–Ω—Ç–∏**: {len(agent_responses)}
- **–ë—Ä–æ–π —Å—ä–æ–±—â–µ–Ω–∏—è**: {len(messages)}
- **–ê–∫—Ç–∏–≤–Ω–∏ –¥–æ–º–µ–π–Ω–∏**: {len(sources_used)}

## üìö **–ù–∞–º–µ—Ä–µ–Ω–∏ –ø—Ä–∞–≤–Ω–∏ —Ü–∏—Ç–∞—Ç–∏** ({len(citations_found)})
{chr(10).join(f"- {citation}" for citation in sorted(citations_found)) if citations_found else "‚ùå –ù—è–º–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏ —Ü–∏—Ç–∞—Ç–∏"}

## üåê **–ò–∑–ø–æ–ª–∑–≤–∞–Ω–∏ –ø—Ä–∞–≤–Ω–∏ –∏–∑—Ç–æ—á–Ω–∏—Ü–∏**
{chr(10).join(f"- {source}" for source in sorted(sources_used)) if sources_used else "‚ùå –ù—è–º–∞ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∏ –¥–æ–º–µ–π–Ω–∏"}

## üéØ **–û–°–ù–û–í–ï–ù –ê–ù–ê–õ–ò–ó**

{final_content}

## üìã **–î–µ—Ç–∞–π–ª–µ–Ω –∞–Ω–∞–ª–∏–∑ –ø–æ –∞–≥–µ–Ω—Ç–∏**
"""
    
    # Add individual agent contributions
    for agent_name, content in agent_responses.items():
        if agent_name and content:
            result += f"\n### ü§ñ **{agent_name}**\n{content[:500]}{'...' if len(content) > 500 else ''}\n"
    
    # Add confidence and coverage metrics
    result += f"""
## üìä **–ö–∞—á–µ—Å—Ç–≤–æ –Ω–∞ –∏–∑—Å–ª–µ–¥–≤–∞–Ω–µ—Ç–æ**
- **–ü–æ–∫—Ä–∏—Ç–∏–µ –Ω–∞ –¥–æ–º–µ–π–Ω–∏**: {len(sources_used)}/{len(BULGARIAN_LEGAL_DOMAINS)}
- **–ü—Ä–∞–≤–Ω–∏ —Ü–∏—Ç–∞—Ç–∏**: {'‚úÖ –î–æ–±—Ä–æ' if len(citations_found) >= 3 else '‚ö†Ô∏è –û–≥—Ä–∞–Ω–∏—á–µ–Ω–æ' if len(citations_found) >= 1 else '‚ùå –ë–µ–∑ —Ü–∏—Ç–∞—Ç–∏'}
- **–ê–≥–µ–Ω—Ç–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞**: {'‚úÖ –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞' if len(agent_responses) >= 3 else '‚ö†Ô∏è –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∞'}

---
*–ì–µ–Ω–µ—Ä–∏—Ä–∞–Ω–æ –æ—Ç Enhanced Bulgarian Legal Research System*
*–ò–∑–ø–æ–ª–∑–≤–∞ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–∞–Ω–∏ –∞–≥–µ–Ω—Ç–∏ –∑–∞ –±—ä–ª–≥–∞—Ä—Å–∫–æ—Ç–æ –ø—Ä–∞–≤–æ –∏ —Å—ä–¥–µ–±–Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–∞*
"""
    
    return result

def get_legal_graph_info():
    """Get comprehensive information about the legal graph structure"""
    graph = build_enhanced_legal_graph()
    graph_dict = graph.get_graph()
    
    info = {
        "nodes": list(graph_dict.nodes.keys()),
        "edges": [(edge.source, edge.target) for edge in graph_dict.edges],
        "entry_point": "Legal_Supervisor",
        "legal_domains": list(BULGARIAN_LEGAL_DOMAINS.keys()),
        "tools_available": [
            "bulgarian_legal_search",
            "legal_document_analyzer", 
            "legal_precedent_search",
            "legal_area_classifier",
            "legal_update_tracker"
        ],
        "specialized_features": [
            "Bulgarian legal domain targeting",
            "Conciliator pattern for conflict resolution",
            "Legal citation extraction",
            "Court precedent analysis",
            "Multi-agent collaboration",
            "Streaming workflow execution"
        ],
        "supported_legal_areas": list(BULGARIAN_LEGAL_AREAS.keys()) if 'BULGARIAN_LEGAL_AREAS' in globals() else []
    }
    
    return info 