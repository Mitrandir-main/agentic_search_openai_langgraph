import json
import time
from langgraph.graph import StateGraph, END
from langchain_core.messages import HumanMessage
from agents import (
    AgentState, 
    create_supervisor, 
    create_bulgarian_legal_search_agent, 
    create_legal_document_analyzer_agent,
    create_legal_citation_specialist_agent,
    get_members
)

def build_graph():
    supervisor_chain = create_supervisor()
    bulgarian_search_node = create_bulgarian_legal_search_agent()
    document_analyzer_node = create_legal_document_analyzer_agent()
    citation_specialist_node = create_legal_citation_specialist_agent()

    graph_builder = StateGraph(AgentState)
    graph_builder.add_node("Supervisor", supervisor_chain)
    graph_builder.add_node("Bulgarian_Legal_Searcher", bulgarian_search_node)
    graph_builder.add_node("Legal_Document_Analyzer", document_analyzer_node)
    graph_builder.add_node("Legal_Citation_Specialist", citation_specialist_node)

    members = get_members()
    for member in members:
        graph_builder.add_edge(member, "Supervisor")

    conditional_map = {k: k for k in members}
    conditional_map["FINISH"] = END
    
    # Update conditional edges to handle the new tool output format
    def route_supervisor(x):
        if isinstance(x, dict) and "args" in x:
            return x["args"]["next"]
        elif isinstance(x, dict) and "next" in x:
            return x["next"]
        else:
            return END
    
    graph_builder.add_conditional_edges("Supervisor", route_supervisor, conditional_map)
    graph_builder.set_entry_point("Supervisor")

    graph = graph_builder.compile()

    return graph

def visualize_graph():
    """Generate and save graph visualization"""
    graph = build_graph()
    try:
        # Try to create PNG visualization
        png_data = graph.get_graph().draw_mermaid_png()
        with open("graph_visualization.png", "wb") as f:
            f.write(png_data)
        print("Graph visualization saved as 'graph_visualization.png'")
        
        # Also create Mermaid text format
        mermaid_syntax = graph.get_graph().draw_mermaid()
        with open("graph_visualization.md", "w") as f:
            f.write("# Bulgarian Legal Research Agent Graph\n\n")
            f.write("```mermaid\n")
            f.write(mermaid_syntax)
            f.write("\n```")
        print("Mermaid syntax saved as 'graph_visualization.md'")
        
        return mermaid_syntax
        
    except Exception as e:
        print(f"Could not generate PNG visualization: {e}")
        # Fallback to text representation
        mermaid_syntax = graph.get_graph().draw_mermaid()
        print("Mermaid Graph Structure:")
        print(mermaid_syntax)
        return mermaid_syntax

def run_graph(input_message, config=None):
    """Run the Bulgarian legal research graph with optional configuration"""
    graph = build_graph()
    
    # Default configuration
    default_config = {
        "query_depth": "medium",
        "complexity_level": "standard", 
        "max_iterations": 3,
        "context_window": 5000,
        "crawling_depth": 2,
        "focus_domains": ["ciela.net", "apis.bg", "lakorda.com"]
    }
    
    if config:
        default_config.update(config)
    
    # Enhanced response processing with configuration
    response = graph.invoke({
        "messages": [HumanMessage(content=input_message)],
        "config": default_config
    })

    # Extract and format the content with better handling
    if not response.get('messages'):
        return "–ù—è–º–∞ –≥–µ–Ω–µ—Ä–∏—Ä–∞–Ω –æ—Ç–≥–æ–≤–æ—Ä."
    
    # Get the last message content
    last_message = response['messages'][-1]
    content = last_message.content if hasattr(last_message, 'content') else str(last_message)

    # Extract sources from all messages for top sources formatting
    all_sources = []
    for msg in response['messages']:
        if hasattr(msg, 'content'):
            msg_content = msg.content
            # Look for sources in the message content 
            if isinstance(msg_content, list):
                for item in msg_content:
                    if isinstance(item, dict) and 'title' in item and 'href' in item:
                        all_sources.append(item)

    # Format the response with top sources at the beginning if not already formatted
    if "üìö **–¢–û–ü 5 –ù–ê–ô-–†–ï–õ–ï–í–ê–ù–¢–ù–ò –ò–ó–¢–û–ß–ù–ò–¶–ò**" not in content and all_sources:
        top_sources = format_top_sources(all_sources[:5])
        result = top_sources + content
    else:
        result = content

    # Add metadata about the processing
    result += f"\n\n---\n*–û–±—Ä–∞–±–æ—Ç–µ–Ω–æ –æ—Ç {len(response['messages'])} –∞–≥–µ–Ω—Ç–Ω–∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è*"
    result += f"\n*–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {default_config['query_depth']} –¥—ä–ª–±–æ—á–∏–Ω–∞, {default_config['complexity_level']} —Å–ª–æ–∂–Ω–æ—Å—Ç*"
    
    return result

def run_graph_with_streaming(input_message, progress_callback=None, config=None):
    """Run graph with streaming for better user experience and progress tracking"""
    graph = build_graph()
    
    # Default configuration
    default_config = {
        "query_depth": "medium",
        "complexity_level": "standard", 
        "max_iterations": 3,
        "context_window": 5000,
        "crawling_depth": 2,
        "focus_domains": ["ciela.net", "apis.bg", "lakorda.com"]
    }
    
    if config:
        default_config.update(config)
    
    print("ü§ñ –ó–∞–ø–æ—á–≤–∞–º –±—ä–ª–≥–∞—Ä—Å–∫–æ –ø—Ä–∞–≤–Ω–æ –∏–∑—Å–ª–µ–¥–≤–∞–Ω–µ...\n")
    
    events_processed = 0
    total_steps = default_config['max_iterations'] * 3  # Estimate based on agents
    
    try:
        for event in graph.stream({
            "messages": [HumanMessage(content=input_message)],
            "config": default_config
        }):
            for key, value in event.items():
                if key != "__end__":
                    events_processed += 1
                    progress = min(events_processed / total_steps, 1.0)
                    
                    # Enhanced progress tracking
                    if progress_callback:
                        if "Bulgarian_Legal_Searcher" in key:
                            progress_callback(f"üîç –¢—ä—Ä—Å—è –≤ –±—ä–ª–≥–∞—Ä—Å–∫–∏ –ø—Ä–∞–≤–Ω–∏ –±–∞–∑–∏ –¥–∞–Ω–Ω–∏...", progress)
                        elif "Legal_Document_Analyzer" in key:
                            progress_callback(f"üìö –ê–Ω–∞–ª–∏–∑–∏—Ä–∞–º –ø—Ä–∞–≤–Ω–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∏...", progress)
                        elif "Legal_Citation_Specialist" in key:
                            progress_callback(f"üìñ –§–æ—Ä–º–∞—Ç–∏—Ä–∞–º —Ñ–∏–Ω–∞–ª–µ–Ω –æ—Ç–≥–æ–≤–æ—Ä...", progress)
                        elif "Supervisor" in key:
                            progress_callback(f"‚öñÔ∏è –ö–æ–æ—Ä–¥–∏–Ω–∏—Ä–∞–º –ø—Ä–∞–≤–Ω–∏—è –∞–Ω–∞–ª–∏–∑...", progress)
                    
                    print(f"üìä **{key}**: {value}")
                    print("---")
                    time.sleep(0.1)  # Small delay for better user experience
        
        # Get final result
        final_response = graph.invoke({
            "messages": [HumanMessage(content=input_message)],
            "config": default_config
        })
        
        return run_graph(input_message, config)  # Use the existing formatting
        
    except Exception as e:
        print(f"–ì—Ä–µ—à–∫–∞ –ø–æ –≤—Ä–µ–º–µ –Ω–∞ —Å—Ç—Ä–∏–π–º–∏–Ω–≥ –∏–∑–ø—ä–ª–Ω–µ–Ω–∏–µ—Ç–æ: {e}")
        return run_graph(input_message, config)  # Fallback to regular execution

def get_graph_info():
    """Get information about the Bulgarian legal graph structure"""
    graph = build_graph()
    graph_dict = graph.get_graph()
    
    info = {
        "nodes": list(graph_dict.nodes.keys()),
        "edges": [(edge.source, edge.target) for edge in graph_dict.edges],
        "entry_point": "Supervisor",
        "specialized_agents": [
            "Bulgarian_Legal_Searcher - –ï–∫—Å–ø–µ—Ä—Ç –ø–æ —Ç—ä—Ä—Å–µ–Ω–µ –≤ –ë–ì –ø—Ä–∞–≤–Ω–∏ –±–∞–∑–∏",
            "Legal_Document_Analyzer - –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–∞ –ø—Ä–∞–≤–Ω–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∏", 
            "Legal_Citation_Specialist - –°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ —Ü–∏—Ç–∞—Ç–∏ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–∞–Ω–µ"
        ],
        "supported_domains": ["ciela.net", "apis.bg", "lakorda.com"],
        "legal_areas": ["–ì—Ä–∞–∂–¥–∞–Ω—Å–∫–æ –ø—Ä–∞–≤–æ", "–ù–∞–∫–∞–∑–∞—Ç–µ–ª–Ω–æ –ø—Ä–∞–≤–æ", "–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω–æ –ø—Ä–∞–≤–æ", "–¢—ä—Ä–≥–æ–≤—Å–∫–æ –ø—Ä–∞–≤–æ", "–¢—Ä—É–¥–æ–≤–æ –ø—Ä–∞–≤–æ"],
        "tools_available": [
            "google_cse_search - Google —Ç—ä—Ä—Å–µ–Ω–µ –∑–∞ –ø—Ä–∞–≤–Ω–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∏",
            "bulgarian_legal_search - –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–∞–Ω–æ –ë–ì –ø—Ä–∞–≤–Ω–æ —Ç—ä—Ä—Å–µ–Ω–µ",
            "legal_precedent_search - –¢—ä—Ä—Å–µ–Ω–µ –Ω–∞ —Å—ä–¥–µ–±–Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–∞",
            "process_content - –ê–Ω–∞–ª–∏–∑ –Ω–∞ –ø—Ä–∞–≤–Ω–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∏"
        ]
    }
    
    return info

def get_config_options():
    """Get available configuration options for the legal research system"""
    return {
        "query_depth": {
            "shallow": "–ü–æ–≤—ä—Ä—Ö–Ω–æ—Å—Ç–Ω–æ —Ç—ä—Ä—Å–µ–Ω–µ - –±—ä—Ä–∑–∏ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏",
            "medium": "–°—Ä–µ–¥–Ω–∞ –¥—ä–ª–±–æ—á–∏–Ω–∞ - –±–∞–ª–∞–Ω—Å–∏—Ä–∞–Ω–æ —Ç—ä—Ä—Å–µ–Ω–µ", 
            "deep": "–î—ä–ª–±–æ–∫–æ —Ç—ä—Ä—Å–µ–Ω–µ - –∏–∑—á–µ—Ä–ø–∞—Ç–µ–ª–µ–Ω –∞–Ω–∞–ª–∏–∑"
        },
        "complexity_level": {
            "basic": "–û—Å–Ω–æ–≤–Ω–æ –Ω–∏–≤–æ - –ø—Ä–æ—Å—Ç–∏ –æ–±—è—Å–Ω–µ–Ω–∏—è",
            "standard": "–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ –Ω–∏–≤–æ - –ø–æ–¥—Ä–æ–±–µ–Ω –∞–Ω–∞–ª–∏–∑",
            "expert": "–ï–∫—Å–ø–µ—Ä—Ç–Ω–æ –Ω–∏–≤–æ - —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ —Å—ä–¥—ä—Ä–∂–∞–Ω–∏–µ"
        },
        "max_iterations": {
            1: "–ë—ä—Ä–∑–æ —Ç—ä—Ä—Å–µ–Ω–µ (1 –∏—Ç–µ—Ä–∞—Ü–∏—è)",
            2: "–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ —Ç—ä—Ä—Å–µ–Ω–µ (2 –∏—Ç–µ—Ä–∞—Ü–∏–∏)", 
            3: "–ó–∞–¥—ä–ª–±–æ—á–µ–Ω–æ —Ç—ä—Ä—Å–µ–Ω–µ (3 –∏—Ç–µ—Ä–∞—Ü–∏–∏)",
            4: "–ò–∑—á–µ—Ä–ø–∞—Ç–µ–ª–Ω–æ —Ç—ä—Ä—Å–µ–Ω–µ (4 –∏—Ç–µ—Ä–∞—Ü–∏–∏)"
        },
        "context_window": {
            2000: "–ú–∞–ª—ä–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç (2K –¥—É–º–∏)",
            5000: "–°—Ä–µ–¥–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç (5K –¥—É–º–∏)",
            8000: "–ì–æ–ª—è–º –∫–æ–Ω—Ç–µ–∫—Å—Ç (8K –¥—É–º–∏)",
            10000: "–ú–∞–∫—Å–∏–º–∞–ª–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç (10K –¥—É–º–∏)"
        },
        "crawling_depth": {
            1: "–°–∞–º–æ –ø—ä—Ä–≤–æ –Ω–∏–≤–æ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∏",
            2: "–î–æ –≤—Ç–æ—Ä–æ –Ω–∏–≤–æ –Ω–∞ –ø—Ä–µ–ø—Ä–∞—Ç–∫–∏",
            3: "–î–æ —Ç—Ä–µ—Ç–æ –Ω–∏–≤–æ –Ω–∞ –ø—Ä–µ–ø—Ä–∞—Ç–∫–∏"
        }
    }

# Helper function to format sources for the response
def format_top_sources(sources, limit=5):
    """Format top sources with metadata for the response"""
    if not sources or not isinstance(sources, list):
        return "üìö **–¢–û–ü 5 –ù–ê–ô-–†–ï–õ–ï–í–ê–ù–¢–ù–ò –ò–ó–¢–û–ß–ù–ò–¶–ò**\n\n–ù—è–º–∞ –Ω–∞–ª–∏—á–Ω–∏ –∏–∑—Ç–æ—á–Ω–∏—Ü–∏.\n\n"
    
    formatted = "üìö **–¢–û–ü 5 –ù–ê–ô-–†–ï–õ–ï–í–ê–ù–¢–ù–ò –ò–ó–¢–û–ß–ù–ò–¶–ò**\n\n"
    
    for i, source in enumerate(sources[:limit], 1):
        if isinstance(source, dict):
            title = source.get('title', '–ë–µ–∑ –∑–∞–≥–ª–∞–≤–∏–µ')
            href = source.get('href', '#')
            body = source.get('body', '')
            domain = source.get('source_domain', '–ù–µ–∏–∑–≤–µ—Å—Ç–µ–Ω –∏–∑—Ç–æ—á–Ω–∏–∫')
            
            # Extract key information for metadata  
            snippet = body[:80] + "..." if len(body) > 80 else body
            
            formatted += f"**{i}. [{title}]({href})**\n"
            formatted += f"   üèõÔ∏è *{domain}*\n" 
            formatted += f"   üìÑ {snippet}\n\n"
    
    formatted += "---\n\n"
    return formatted

def extract_sources_from_response(response_messages):
    """Extract sources from response messages for formatting"""
    sources = []
    
    for message in response_messages:
        content = message.content if hasattr(message, 'content') else str(message)
        
        # Look for source patterns in the content
        import re
        
        # Pattern to match source dictionaries or lists
        if isinstance(content, list):
            for item in content:
                if isinstance(item, dict) and 'title' in item and 'href' in item:
                    sources.append(item)
        elif hasattr(content, 'sources') or 'title' in str(content):
            # Try to extract sources from content
            continue
    
    return sources